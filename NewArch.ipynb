{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bfb776c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import models,Sequential,constraints\n",
    "from tensorflow.keras.layers import Conv1D,MaxPooling1D,Dropout,Dense,Flatten,Layer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,hamming_loss\n",
    "from sklearn.utils import class_weight\n",
    "from tensorflow.keras import backend as K\n",
    "import tensorflow_addons as tfa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot,colors\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57348630",
   "metadata": {},
   "outputs": [],
   "source": [
    "spectra=pd.read_csv('C:\\Users\\ks\\Desktop\\Spectra Identification\\Spectra_Checked_baseline.csv',header=0) # Read spectra data\n",
    "X=spectra.iloc[:,1:].values\n",
    "labels=pd.read_csv('Labels_Checked_baseline.csv',header=0) # Read labels data\n",
    "Y=labels.iloc[:,1:].values\n",
    "X=X_data.transpose()\n",
    "Y=Y_data.transpose()\n",
    "X_train, X_test, y_train, y_test= train_test_split(X, Y, test_size=0.3, random_state=42)\n",
    "X_train=np.expand_dims(X_train,axis=2) # Expand to include channel axis for CNN\n",
    "X_test=np.expand_dims(X_test,axis=2)# Expand to include channel axis for CNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7986520b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of custom Keras layer for Lorentzians\n",
    "class Lorentz_layer(Layer):\n",
    "    def __init__(self, units=5,kernel_constraint=None,\n",
    "               bias_constraint=None,**kwargs):\n",
    "        super(Lorentz_layer,self).__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.kernel_constraint = constraints.get(kernel_constraint)\n",
    "        self.bias_constraint = constraints.get(bias_constraint)\n",
    "        \n",
    "    def build(self,input_shape):\n",
    "        self.w = tf.Variable(name=\"kernel\",   initial_value=90*tf.eye(input_shape[-1], num_columns=self.units,\n",
    "                 dtype='float32'),constraint=self.kernel_constraint,trainable=True)\n",
    "        \n",
    "        b_init = tf.keras.initializers.RandomUniform(minval=0, maxval=100, seed=None)\n",
    "        self.b = tf.Variable(name=\"bias\",initial_value=b_init(shape=(self.units,), dtype='float32'),\n",
    "                             constraint=self.bias_constraint,\n",
    "                             trainable=True)\n",
    "        self.x=(np.linspace(0,3600,901,dtype='float32')).reshape(901,1)\n",
    "    \n",
    "    def call(self,inputs):\n",
    "        x0=tf.matmul(inputs,self.w)+K.epsilon()\n",
    "        gamma=self.b+K.epsilon()\n",
    "        val=(1/(np.pi*gamma))*(1/(1+(tf.subtract(self.x,tf.expand_dims(x0,axis=1))/gamma)**2))\n",
    "        return val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d031e26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of custom layer for summation of Cauchy distributions\n",
    "class sum_layer(Layer):\n",
    "    def __init__(self, units=1,kernel_constraint=None,\n",
    "               bias_constraint=None,**kwargs):\n",
    "        super(sum_layer,self).__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.kernel_constraint = constraints.get(kernel_constraint)\n",
    "        self.bias_constraint = constraints.get(bias_constraint)\n",
    "    def build(self,input_shape):\n",
    "        w_init = tf.keras.initializers.RandomUniform(minval=0.01, maxval=1, seed=None)\n",
    "        self.w = tf.Variable(name=\"kernel\",   initial_value=w_init(shape=(input_shape[-1], self.units),\n",
    "                 dtype='float32'),constraint=self.kernel_constraint,trainable=True)\n",
    "        \n",
    "        self.b = None\n",
    "    def call(self,inputs):\n",
    "        val=tf.matmul(inputs,self.w)\n",
    "        val=tf.divide(tf.subtract(val, tf.reduce_min(val)), tf.subtract(tf.reduce_max(val), tf.reduce_min(val))+K.epsilon())\n",
    "        return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d31be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Keras model structure\n",
    "my_layer=Lorentz_layer(units=15,kernel_constraint=constraints.NonNeg(),bias_constraint=constraints.NonNeg())\n",
    "final_layer=sum_layer(kernel_constraint=constraints.NonNeg())\n",
    "Input_layer=keras.Input(shape=(901,1))\n",
    "conv1=Conv1D(filters=10, kernel_size=5,activation='relu',padding='same')\n",
    "pool1=MaxPooling1D()\n",
    "pool2=MaxPooling1D()\n",
    "conv2=Conv1D(filters=10, kernel_size=5,activation='relu',padding='same')\n",
    "drop=Dropout(0.5)\n",
    "flat=Flatten()\n",
    "Dense1=Dense(20,activation='relu')\n",
    "Dense2=Dense(20,activation='relu')\n",
    "Dense3=Dense(15,activation='relu',name='X0')\n",
    "Sig=Dense(14,activation='sigmoid',name='Labels')\n",
    "x=conv1(Input_layer)\n",
    "x=pool1(x)\n",
    "x=conv2(x)\n",
    "x=pool2(x)\n",
    "x=drop(x)\n",
    "x=flat(x)\n",
    "\n",
    "x=Dense1(x)\n",
    "x=Dense3(x)\n",
    "op_label=Sig(x)\n",
    "y=Dense2(x)\n",
    "spec=my_layer(y)\n",
    "op_spec=final_layer(spec)\n",
    "\n",
    "model=keras.Model(Input_layer,[op_label,op_spec])\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a3652a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weighting loss function for less represented classes\n",
    "def calculating_class_weights(y_true):\n",
    "    from sklearn.utils.class_weight import compute_class_weight\n",
    "    number_dim = np.shape(y_true)[1]\n",
    "    weights = np.empty([number_dim, 2])\n",
    "    for i in range(number_dim):\n",
    "        weights[i] = compute_class_weight('balanced', classes=[0.,1.], y=y_true[:, i])\n",
    "    return weights\n",
    "weights=calculating_class_weights(y_train)\n",
    "def get_weighted_loss(weights):\n",
    "    def weighted_loss(y_true, y_pred):\n",
    "        y_true=tf.cast(y_true,tf.float32)\n",
    "        y_pred=tf.cast(y_pred,tf.float32)\n",
    "        return K.mean((weights[:,0]**(1-y_true))*(weights[:,1]**(y_true))*K.binary_crossentropy(y_true, y_pred), axis=-1)\n",
    "    return weighted_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39d1372",
   "metadata": {},
   "outputs": [],
   "source": [
    "def KLDerror(y_true,y_pred):\n",
    "    x=K.softmax(y_true,axis=1)\n",
    "    y=K.softmax(y_pred,axis=1)\n",
    "    kl=keras.losses.KLDivergence()\n",
    "    return kl(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526d7a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "opt = keras.optimizers.Adam(learning_rate=1E-3) #Set learning rate and optimizer\n",
    "model.compile(loss=[get_weighted_loss(weights),KLDerror],optimizer=opt,loss_weights=[1,500]) # Realtive importance of each loss\n",
    "history=model.fit(X_train,[y_train,X_train],epochs=3000,validation_data=(X_test, [y_test,X_test]),verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615af8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('C:\\Users\\ks\\Desktop\\Spectra Identification\\SavedModels\\NewArch_Water')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4ef13e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
